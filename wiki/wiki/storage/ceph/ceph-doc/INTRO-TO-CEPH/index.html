<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="INTRO TO CEPH  HARDWARE RECOMMENDATIONS
 OS RECOMMENDATIONS
 GET INVOLVED IN THE CEPH COMMUNITY!
 DOCUMENTING CEPH
INTRO TO CEPH Whether you want to provideÂ Ceph Object StorageÂ and/orÂ Ceph Block DeviceÂ services toÂ Cloud Platforms, deploy aÂ Ceph File SystemÂ or use Ceph for another purpose, allÂ Ceph Storage ClusterÂ deployments begin with setting up eachÂ Ceph Node, your network, and the Ceph Storage Cluster."><title>INTRO_TO_CEPH</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://lzyerste.github.io/quartz//icon.png><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Source+Sans+Pro:wght@400;600;700&family=Fira+Code:wght@400;700&display=swap" rel=stylesheet><link href=https://lzyerste.github.io/quartz/styles.48db36360688fe00f0a39f3cf1417c4b.min.css rel=stylesheet><script src=https://lzyerste.github.io/quartz/js/darkmode.46b07878b7f5d9e26ad7a3c40f8a0605.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><script>const BASE_URL="https://lzyerste.github.io/quartz/",fetchData=Promise.all([fetch("https://lzyerste.github.io/quartz/indices/linkIndex.d9d5859c0e0b3db667123f4df2b3a95c.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://lzyerste.github.io/quartz/indices/contentIndex.8142ea9941fd6973dd3e16e4214a0035.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n}))</script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-XYFD95KB4J"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XYFD95KB4J",{anonymize_ip:!1})}</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://lzyerste.github.io/quartz/js/search.7861a82db330f0a40935b7458fee3a02.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://lzyerste.github.io/quartz/>ðŸª´ Quartz 3.2</a></h1><svg tabindex="0" id="search-icon" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg><div class=spacer></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>INTRO_TO_CEPH</h1><p class=meta>Last updated May 1, 2022</p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents></nav></details></aside><h1 id=intro-to-ceph>INTRO TO CEPH</h1><p><a href=/quartz/wiki/wiki/storage/ceph/ceph-doc/INTRO-TO-CEPH/HARDWARE-RECOMMENDATIONS-294f3f32fec34da5b953a38eb4627119 rel=noopener class=internal-link data-src=/quartz/wiki/wiki/storage/ceph/ceph-doc/INTRO-TO-CEPH/HARDWARE-RECOMMENDATIONS-294f3f32fec34da5b953a38eb4627119>HARDWARE RECOMMENDATIONS</a></p><p><a href=/quartz/wiki/wiki/storage/ceph/ceph-doc/INTRO-TO-CEPH/OS-RECOMMENDATIONS-72e2a23432904fd99e724a9c763e08fa rel=noopener class=internal-link data-src=/quartz/wiki/wiki/storage/ceph/ceph-doc/INTRO-TO-CEPH/OS-RECOMMENDATIONS-72e2a23432904fd99e724a9c763e08fa>OS RECOMMENDATIONS</a></p><p><a href=/quartz/wiki/wiki/storage/ceph/ceph-doc/INTRO-TO-CEPH/GET-INVOLVED-IN-THE-CEPH-COMMUNITY-29e5b2a8c4034e4bb0f9c9e2b7b0e6b2 rel=noopener class=internal-link data-src=/quartz/wiki/wiki/storage/ceph/ceph-doc/INTRO-TO-CEPH/GET-INVOLVED-IN-THE-CEPH-COMMUNITY-29e5b2a8c4034e4bb0f9c9e2b7b0e6b2>GET INVOLVED IN THE CEPH COMMUNITY!</a></p><p><a href=/quartz/wiki/wiki/storage/ceph/ceph-doc/INTRO-TO-CEPH/DOCUMENTING-CEPH-d2b83f89d09d4846be712e5562827f54 rel=noopener class=internal-link data-src=/quartz/wiki/wiki/storage/ceph/ceph-doc/INTRO-TO-CEPH/DOCUMENTING-CEPH-d2b83f89d09d4846be712e5562827f54>DOCUMENTING CEPH</a></p><h1 id=intro-to-ceph-1>INTRO TO CEPH</h1><p>Whether you want to provideÂ 
<a href=https://docs.ceph.com/docs/master/glossary/#term-ceph-object-storage rel=noopener>Ceph Object Storage</a>Â and/orÂ 
<a href=https://docs.ceph.com/docs/master/glossary/#term-ceph-block-device rel=noopener>Ceph Block Device</a>Â services toÂ 
<a href=https://docs.ceph.com/docs/master/glossary/#term-cloud-platforms rel=noopener>Cloud Platforms</a>, deploy aÂ 
<a href=https://docs.ceph.com/docs/master/glossary/#term-ceph-file-system rel=noopener>Ceph File System</a>Â or use Ceph for another purpose, allÂ 
<a href=https://docs.ceph.com/docs/master/glossary/#term-ceph-storage-cluster rel=noopener>Ceph Storage Cluster</a>Â deployments begin with setting up eachÂ 
<a href=https://docs.ceph.com/docs/master/glossary/#term-ceph-node rel=noopener>Ceph Node</a>, your network, and the Ceph Storage Cluster. A Ceph Storage Cluster requires at least one Ceph Monitor, Ceph Manager, and Ceph OSD (Object Storage Daemon). The Ceph Metadata Server is also required when running Ceph File System clients.</p><p><img src=https://docs.ceph.com/docs/master/_images/ditaa-a05b27b38a4e3f935204a86447596829bf691c9e.png alt=https://docs.ceph.com/docs/master/_images/ditaa-a05b27b38a4e3f935204a86447596829bf691c9e.png></p><ul><li><strong>Monitors</strong>: AÂ 
<a href=https://docs.ceph.com/docs/master/glossary/#term-ceph-monitor rel=noopener>Ceph Monitor</a>Â (<code>ceph-mon</code>) maintains maps of the cluster state, including the monitor map, manager map, the OSD map, the MDS map, and the CRUSH map. These maps are critical cluster state required for Ceph daemons to coordinate with each other. Monitors are also responsible for managing authentication between daemons and clients. At least three monitors are normally required for redundancy and high availability.</li><li><strong>Managers</strong>: AÂ 
<a href=https://docs.ceph.com/docs/master/glossary/#term-ceph-manager rel=noopener>Ceph Manager</a>Â daemon (<code>ceph-mgr</code>) is responsible for keeping track of runtime metrics and the current state of the Ceph cluster, including storage utilization, current performance metrics, and system load. The Ceph Manager daemons also host python-based modules to manage and expose Ceph cluster information, including a web-basedÂ 
<a href=https://docs.ceph.com/docs/master/mgr/dashboard/#mgr-dashboard rel=noopener>Ceph Dashboard</a>Â andÂ 
<a href=https://docs.ceph.com/docs/master/mgr/restful rel=noopener>REST API</a>. At least two managers are normally required for high availability.</li><li><strong>Ceph OSDs</strong>: AÂ 
<a href=https://docs.ceph.com/docs/master/glossary/#term-ceph-osd rel=noopener>Ceph OSD</a>Â (object storage daemon,Â <code>ceph-osd</code>) stores data, handles data replication, recovery, rebalancing, and provides some monitoring information to Ceph Monitors and Managers by checking other Ceph OSD Daemons for a heartbeat. At least 3 Ceph OSDs are normally required for redundancy and high availability.</li><li><strong>MDSs</strong>: AÂ 
<a href=https://docs.ceph.com/docs/master/glossary/#term-ceph-metadata-server rel=noopener>Ceph Metadata Server</a>Â (MDS,Â <code>ceph-mds</code>) stores metadata on behalf of theÂ 
<a href=https://docs.ceph.com/docs/master/glossary/#term-ceph-file-system rel=noopener>Ceph File System</a>Â (i.e., Ceph Block Devices and Ceph Object Storage do not use MDS). Ceph Metadata Servers allow POSIX file system users to execute basic commands (likeÂ <code>ls</code>,Â <code>find</code>, etc.) without placing an enormous burden on the Ceph Storage Cluster.</li></ul><p>Ceph stores data as objects within logical storage pools. Using theÂ 
<a href=https://docs.ceph.com/docs/master/glossary/#term-crush rel=noopener>CRUSH</a>Â algorithm, Ceph calculates which placement group should contain the object, and further calculates which Ceph OSD Daemon should store the placement group. The CRUSH algorithm enables the Ceph Storage Cluster to scale, rebalance, and recover dynamically.</p></article><hr><div class=page-end><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div></div><div id=contact_buttons><footer><p>Made by Jacky Zhao using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, Â© 2022</p><ul><li><a href=/>Home</a></li><li><a href=https://twitter.com/_jzhao>Twitter</a></li><li><a href=https://github.com/jackyzha0>Github</a></li></ul></footer></div><script src=https://lzyerste.github.io/quartz/js/popover.e57188d2e4c06b0654e020b3a734bb62.min.js></script>
<script>initPopover("https://lzyerste.github.io/quartz")</script></div></body></html>