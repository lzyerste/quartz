<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Transparent Hugepages: measuring the performance impact - The mole is digging  https://alexandrnikitin.github.io/blog/transparent-hugepages-measuring-the-performance-impact/
TL;DR This post explains Transparent Hugepages (THP) in a nutshell, describes techniques that can be used to measure the performance impact, shows the effect on a real-world application."><title>Transparent_Hugepages_measuring_the_performance_im</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://lzyerste.github.io/quartz//icon.png><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Source+Sans+Pro:wght@400;600;700&family=Fira+Code:wght@400;700&display=swap" rel=stylesheet><link href=https://lzyerste.github.io/quartz/styles.48db36360688fe00f0a39f3cf1417c4b.min.css rel=stylesheet><script src=https://lzyerste.github.io/quartz/js/darkmode.46b07878b7f5d9e26ad7a3c40f8a0605.min.js></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><script>const BASE_URL="https://lzyerste.github.io/quartz/",fetchData=Promise.all([fetch("https://lzyerste.github.io/quartz/indices/linkIndex.2e6129a8792c8eebefa64fbcd3ffe852.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://lzyerste.github.io/quartz/indices/contentIndex.ce2453c5c9ff5c0ddce4edb9aef38d63.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n}))</script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-XYFD95KB4J"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XYFD95KB4J",{anonymize_ip:!1})}</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://lzyerste.github.io/quartz/js/search.7861a82db330f0a40935b7458fee3a02.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://lzyerste.github.io/quartz/>🪴 Quartz 3.2</a></h1><svg tabindex="0" id="search-icon" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg><div class=spacer></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>Transparent_Hugepages_measuring_the_performance_im</h1><p class=meta>Last updated June 3, 2022</p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#transparent-hugepages-in-a-nutshell>Transparent Hugepages in a nutshell</a></li><li><a href=#how-to-measure>How to measure?</a></li><li><a href=#jvm>JVM</a></li><li><a href=#a-real-world-case-high-load-jvm>A real-world case: High-load JVM</a><ol><li><a href=#transparent-hugepages-is-off>Transparent Hugepages is off</a></li><li><a href=#transparent-hugepages-is-on>Transparent Hugepages is on</a></li></ol></li><li><a href=#conclusion>Conclusion</a></li></ol></nav></details></aside><h1 id=transparent-hugepages-measuring-the-performance-impact---the-mole-is-digging>Transparent Hugepages: measuring the performance impact - The mole is digging</h1><p><a href=https://alexandrnikitin.github.io/blog/transparent-hugepages-measuring-the-performance-impact/ rel=noopener>https://alexandrnikitin.github.io/blog/transparent-hugepages-measuring-the-performance-impact/</a></p><p>TL;DR This post explains Transparent Hugepages (THP) in a nutshell, describes techniques that can be used to measure the performance impact, shows the effect on a real-world application.</p><p>The post was inspired by
<a href=https://groups.google.com/forum/#!topic/mechanical-sympathy/sljzehnCNZU rel=noopener>a thread about Transparent Hugepages</a> on the Mechanical Sympathy group. The thread walks through the pitfalls, performance numbers and current state in the latest kernel versions. A lot of useful information is there. In general, you can find many recommendations on the Internet. Many of them tell you to disable THP, e.g.
<a href=http://docs.oracle.com/cd/E11882_01/install.112/e47689/pre_install.htm#LADBI1519 rel=noopener>Oracle Database</a>,
<a href=https://docs.mongodb.com/manual/tutorial/transparent-huge-pages/ rel=noopener>MongoDB</a>,
<a href=https://developer.couchbase.com/documentation/server/current/install/thp-disable.html rel=noopener>Couchbase</a>,
<a href=https://help.memsql.com/hc/en-us/articles/115002948663-Disable-Transparent-Huge-Pages rel=noopener>MemSQL</a>,
<a href=http://doc.nuodb.com/Latest/Content/Note-About--Using-Transparent-Huge-Pages.htm rel=noopener>NuoDB</a> . Few of them utilize the feature, e.g.
<a href=https://www.postgresql.org/docs/9.6/static/kernel-resources.html#LINUX-HUGE-PAGES rel=noopener>PostgreSQL</a> (hugetlbpage feature, not THP) and
<a href=https://my.vertica.com/docs/7.2.x/HTML/index.htm#Authoring/InstallationGuide/BeforeYouInstall/transparenthugepages.htm rel=noopener>Vertica</a>. There are quite a few stories telling how people fight a system freeze and solved it disabling the THP feature.
<a href=https://www.perforce.com/blog/tales-field-taming-transparent-huge-pages-linux rel=noopener>1</a>,
<a href=https://community.microfocus.com/borland/managetrack/accurev/w/accurev_knowledge_base/27749/recommendation-to-disable-linux-kernel-transparent-hugepages-thp-setting-for-performance-improvement rel=noopener>2</a>,
<a href=http://structureddata.org/2012/06/18/linux-6-transparent-huge-pages-and-hadoop-workloads/ rel=noopener>3</a>,
<a href=https://blogs.oracle.com/linux/performance-issues-with-transparent-huge-pages-thp rel=noopener>4</a>,
<a href=https://dzone.com/articles/why-tokudb-hates-transparent rel=noopener>5</a>,
<a href=https://engineering.linkedin.com/performance/optimizing-linux-memory-management-low-latency-high-throughput-databases rel=noopener>6</a>. All those stories lead to distorted view and preconception that the feature is harmful.</p><p>Unfortunately, I couldn’t find any post that measures or shows how to measure the impact and consequences of enabling/ disabling the feature. This is what this post is supposed to address.</p><h2 id=transparent-hugepages-in-a-nutshell>Transparent Hugepages in a nutshell</h2><p>Almost all applications and OSes run in virtual memory. Virtual memory is mapped into physical memory. The mapping is managed by an OS maintaining
<a href=https://en.wikipedia.org/wiki/Page_table rel=noopener>the page tables data structure</a> in RAM. The address translation logic (page table walking) is implemented by
<a href=https://en.wikipedia.org/wiki/Memory_management_unit rel=noopener>the CPU’s memory management unit (MMU)</a>. The MMU also has a cache of recently used pages. This cache is called the Translation lookaside buffer (TLB).</p><p>“When a virtual address needs to be translated into a physical address, the TLB is searched first. If a match is found (a TLB hit), the physical address is returned and memory access can continue. However, if there is no match (called a TLB miss), the MMU will typically look up the address mapping in the page table to see whether a mapping exists.” The page table walk is expensive because it may require multiple memory accesses (they may hit the CPU L1/L2/L3 caches though). On the other side, the TLB cache size is limited and typically can hold several hundred pages.</p><p>OSes manage virtual memory using pages (contiguous block of memory). Typically, the size of a memory page is 4 KB. 1 GB of memory is 256 000 pages; 128 GB is 32 768 000 pages. Obviously TLB cache can’t fit all of the pages and performance suffers from cache misses. There are two main ways to improve it. The first one is to increase TLB size, which is expensive and won’t help significantly. Another one is to increase the page size and therefore have less pages to map. Modern OSes and CPUs support large 2 MB and even 1 GB pages. Using large 2 MB pages, 128 GB of memory becomes just 64 000 pages.</p><p>That’s the reason there is Linux Transparent Hugepage Support in Linux. It’s an optimization! It manages large pages automatically and transparently for applications. The benefits are pretty obvious: no changes required on application side; it reduces the number of TLB misses; page table walking becomes cheaper. The feature logically can be divided into two parts: allocation and maintenance. The THP takes the regular (“higher-order”) memory allocation path and it requires that the OS be able to find contiguous and aligned block of memory. It suffers from the same issues as the regular pages, namely fragmentation. If the OS can’t find a contiguous block of memory, it will try to compact, reclaim or page out other pages. That process is expensive and <strong>could cause latency spikes (up to seconds)</strong>. This issue was addressed in the 4.6 kernel (via “defer” option), the OS falls back to a regular page if it can’t allocate a large one. The second part is maintenance. Even if an application touches just 1 byte of memory, it will consume whole 2 MB large page. This is obviously a waste of memory. So there’s a background kernel thread called “khugepaged”. It scans pages and tries to defragment and collapse them into one huge page. Despite it’s a background thread, it locks pages it works with, hence <strong>could cause latency spikes</strong> too. Another pitfall lays in large page splitting, not all parts of the OS work with large pages, e.g. swap. The OS splits large pages into regular ones for them. It could also degrade the performance and increase memory fragmentation.</p><p>The best place to read about Transparent Hugepage Support is the official documentation on
<a href=https://www.kernel.org/doc/Documentation/vm/transhuge.txt rel=noopener>the Linux Kernel website</a>. The feature has several settings and flags that affect its behavior and they evolve with the Linux kernel.</p><h2 id=how-to-measure>How to measure?</h2><p>This is the most crucial part and the goal of this post. Basically there are two ways to measure the impact: CPU counters and kernel functions.</p><p>Let’s start from the CPU counters. I use
<a href=https://perf.wiki.kernel.org/index.php/Main_Page rel=noopener>perf</a>, which is a great and easy-to-use tool for that purpose. Perf has built-in event aliases for TLB: <code>dTLB-loads</code>, <code>dTLB-load-misses</code> for data loads hits and misses; <code>dTLB-stores</code>, <code>dTLB-store-misses</code> for data stores hits and misses.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[~]# perf stat -e dTLB-loads,dTLB-load-misses,dTLB-stores,dTLB-store-misses -a -I 1000
</span></span><span class=line><span class=cl>#           time             counts unit events
</span></span><span class=line><span class=cl>     1.006223197         85,144,535      dTLB-loads                                                    
</span></span><span class=line><span class=cl>     1.006223197          1,153,457      dTLB-load-misses          #    1.35% of all dTLB cache hits   
</span></span><span class=line><span class=cl>     1.006223197        153,092,544      dTLB-stores                                                   
</span></span><span class=line><span class=cl>     1.006223197            213,524      dTLB-store-misses                                             
</span></span><span class=line><span class=cl>...
</span></span></code></pre></td></tr></table></div></div><p>Let’s not forget about instruction misses too: <code>iTLB-load</code>, <code>iTLB-load-misses</code>.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[~]# perf stat -e iTLB-load,iTLB-load-misses -a -I 1000
</span></span><span class=line><span class=cl>#           time             counts unit events
</span></span><span class=line><span class=cl>     1.005591635              5,496      iTLB-load
</span></span><span class=line><span class=cl>     1.005591635             18,799      iTLB-load-misses          #  342.05% of all iTLB cache hits
</span></span><span class=line><span class=cl>...
</span></span></code></pre></td></tr></table></div></div><p>In fact, perf supports just a small subset of all events while CPUs have hundreds of various counters to monitor the performance. For Intel CPUs you can find all available counters on the
<a href=https://download.01.org/perfmon/index/ rel=noopener>Intel Processor Event Reference website</a> or in
<a href=https://www.intel.com/content/www/us/en/architecture-and-technology/64-ia-32-architectures-software-developer-vol-3b-part-2-manual.html rel=noopener>“Intel® 64 and IA-32 Architectures Developer’s Manual: Vol. 3B”</a> or in
<a href=https://github.com/torvalds/linux/blob/510c8a899caf095cb13d09d203573deef15db2fe/tools/perf/pmu-events/arch/x86/haswell/virtual-memory.json rel=noopener>the Linux kernel sources</a>. The Developer’s Manual also contains event codes that we need to pass to perf.</p><p>If we take a look at the TLB related counters, we could find the following most interesting for us:</p><p><a rel=noopener class="internal-link broken" data-src=assets/Untitled%20Database%20aac6c48ab7374ce8ad15a598fc40b4c5.csv>Untitled</a></p><p>Perf supports the <code>*MISS_CAUSES_A_WALK</code> counters via aliases. We need to use event numbers for others. The CPU event numbers and umask values are CPU specific; the listed above are for the Haswell microarchitecture. You need to look for codes for your CPU.</p><p>One of the key metrics is the number of CPU cycles spent in the page table walking:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[~]# perf stat -e cycles \
</span></span><span class=line><span class=cl>&gt;   -e cpu/event=0x08,umask=0x10,name=dcycles/ \
</span></span><span class=line><span class=cl>&gt;   -e cpu/event=0x85,umask=0x10,name=icycles/ \
</span></span><span class=line><span class=cl>&gt;   -a -I 1000
</span></span><span class=line><span class=cl>#           time             counts unit events
</span></span><span class=line><span class=cl>     1.005079845        227,119,840      cycles
</span></span><span class=line><span class=cl>     1.005079845          2,605,237      dcycles
</span></span><span class=line><span class=cl>     1.005079845            806,076      icycles
</span></span><span class=line><span class=cl>...
</span></span></code></pre></td></tr></table></div></div><p>Another important metric is the number of main memory reads caused by TLB miss; those reads miss the CPU caches hence quite expensive:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@PRCAPISV0003L01 ~]# perf stat -e cache-misses \
</span></span><span class=line><span class=cl>&gt;   -e cpu/event=0xbc,umask=0x18,name=dreads/ \
</span></span><span class=line><span class=cl>&gt;   -e cpu/event=0xbc,umask=0x28,name=ireads/ \
</span></span><span class=line><span class=cl>&gt;   -a -I 1000
</span></span><span class=line><span class=cl>#           time             counts unit events
</span></span><span class=line><span class=cl>     1.007177568             25,322      cache-misses
</span></span><span class=line><span class=cl>     1.007177568                 23      dreads
</span></span><span class=line><span class=cl>     1.007177568                  5      ireads
</span></span><span class=line><span class=cl>...
</span></span></code></pre></td></tr></table></div></div><p>Another powerful way to measure how TPH affects performance and latency is tracing/ probing Linux kernel functions. I use
<a href=https://sourceware.org/systemtap/ rel=noopener>SystemTap</a> for that, which is “a tool for dynamically instrumenting running production Linux kernel-based operating systems.”</p><p>The first function that is interesting for us is <code>[__alloc_pages_slowpath](http://elixir.free-electrons.com/linux/v3.10/source/mm/page_alloc.c#L2391)</code>. It is executed when there’s no contiguous block of memory available for allocation. In its turn, this function calls expensive page compaction and reclamation logic that could cause latency spikes.</p><p>The second interesting function is <code>[khugepaged_scan_mm_slot](http://elixir.free-electrons.com/linux/v3.10/source/mm/huge_memory.c#L2466)</code>. It is executed by the background “khugepaged” kernel thread. It scans hugepages and tries to collapse them into one.</p><p>I use a SystemTap script to measure a function execution latency. The script stores all execution timings in microseconds and periodically outputs a logarithmic histogram. It consumes few megabytes per hour depending on number of executions. The first argument is a probe point, the second one is number of milliseconds to periodically print statistics.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>#! /usr/bin/env stap
</span></span><span class=line><span class=cl>global start, intervals
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>probe $1 { start[tid()] = gettimeofday_us() }
</span></span><span class=line><span class=cl>probe $1.return
</span></span><span class=line><span class=cl>{
</span></span><span class=line><span class=cl>  t = gettimeofday_us()
</span></span><span class=line><span class=cl>  old_t = start[tid()]
</span></span><span class=line><span class=cl>  if (old_t) intervals &lt;&lt;&lt; t - old_t
</span></span><span class=line><span class=cl>  delete start[tid()]
</span></span><span class=line><span class=cl>}
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>probe timer.ms($2)
</span></span><span class=line><span class=cl>{
</span></span><span class=line><span class=cl>    if (@count(intervals) &gt; 0)
</span></span><span class=line><span class=cl>    {
</span></span><span class=line><span class=cl>        printf(&#34;%-25s:\n min:%dus avg:%dus max:%dus count:%d \n&#34;, tz_ctime(gettimeofday_s()),
</span></span><span class=line><span class=cl>             @min(intervals), @avg(intervals), @max(intervals), @count(intervals))
</span></span><span class=line><span class=cl>        print(@hist_log(intervals));
</span></span><span class=line><span class=cl>    }
</span></span><span class=line><span class=cl>}
</span></span></code></pre></td></tr></table></div></div><p>Here’s an example for the <code>__alloc_pages_slowpath</code> function:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[~]# ./func_time_stats.stp &#39;kernel.function(&#34;__alloc_pages_slowpath&#34;)&#39; 1000
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Thu Aug 17 09:37:19 2017 CEST:
</span></span><span class=line><span class=cl> min:0us avg:1us max:23us count:1538
</span></span><span class=line><span class=cl>value |-------------------------------------------------- count
</span></span><span class=line><span class=cl>    0 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@  549
</span></span><span class=line><span class=cl>    1 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@  541
</span></span><span class=line><span class=cl>    2 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@                 377
</span></span><span class=line><span class=cl>    4 |@@@@                                                54
</span></span><span class=line><span class=cl>    8 |@                                                   12
</span></span><span class=line><span class=cl>   16 |                                                     5
</span></span><span class=line><span class=cl>   32 |                                                     0
</span></span><span class=line><span class=cl>   64 |                                                     0
</span></span><span class=line><span class=cl>...
</span></span></code></pre></td></tr></table></div></div><p>It’s also worth to monitor the overall system state. For example the memory fragmentation state. <code>/proc/buddyinfo</code> “is a useful tool for helping diagnose these problems. Buddyinfo will give you a clue as to how big an area you can safely allocate, or why a previous allocation failed.” More information relevant to fragmentation can also be found in <code>/proc/pagetypeinfo</code>.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>cat /proc/buddyinfo
</span></span><span class=line><span class=cl>cat /proc/pagetypeinfo
</span></span></code></pre></td></tr></table></div></div><p>You can read more about it in
<a href=http://elixir.free-electrons.com/linux/v3.10.107/source/Documentation/filesystems/proc.txt#L691 rel=noopener>the official documentation</a> or
<a href=http://andorian.blogspot.lt/2014/03/making-sense-of-procbuddyinfo.html rel=noopener>in this post</a>.</p><h2 id=jvm>JVM</h2><p>JVM supports Transparent Hugepages via the <code>-XX:+UseTransparentHugePages</code> flag. Although they warn about possible performance problems:</p><blockquote><p>-XX:+UseTransparentHugePages On Linux, enables the use of large pages that can dynamically grow or shrink. This option is disabled by default. You may encounter performance problems with transparent huge pages as the OS moves other pages around to create huge pages; this option is made available for experimentation.</p></blockquote><p>It is worth to enable the use of large pages for Metaspace too:</p><blockquote><p>-XX:+UseLargePagesInMetaspace Use large page memory in metaspace. Only used if UseLargePages is enabled.</p></blockquote><p>It may be a good idea to use hugepages with <code>-XX:+AlwaysPreTouch</code> options. It preallocates all physical memory used by the heap, hence avoids any further overhead for page initialization or compaction. But it takes more time to initialize the JVM.</p><blockquote><p>-XX:+AlwaysPreTouch Enables touching of every page on the Java heap during JVM initialization. This gets all pages into the memory before entering the main() method. The option can be used in testing to simulate a long-running system with all virtual memory mapped to physical memory. By default, this option is disabled and all pages are committed as JVM heap space fills.</p></blockquote><p><a href=http://twitter.com/shipilev rel=noopener>Aleksey Shipilёv</a> shows performance impact in microbenchmarks in
<a href=https://shipilev.net/jvm-anatomy-park/2-transparent-huge-pages/ rel=noopener>his “JVM Anatomy Park #2: Transparent Huge Pages” blog post</a>.</p><h2 id=a-real-world-case-high-load-jvm>A real-world case: High-load JVM</h2><p>Let’s take a look at how Transparent Hugepages affect a real-world application. Given a JVM application: a high-load TCP server based on
<a href=https://netty.io/ rel=noopener>netty</a>. The server receives up to 100K requests per second, parses them, performs a network database call for each one, then does quite a lot of computations and returns a response back. The JVM application has 200 GB heap. The measurements were done on production servers and production load. Servers were not overloaded and received a half of the maximum number of requests they can handle.</p><h3 id=transparent-hugepages-is-off>Transparent Hugepages is off</h3><p>Let’s turn the THP off:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled
</span></span><span class=line><span class=cl>echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag
</span></span></code></pre></td></tr></table></div></div><p>The first thing to measure is the number of TLB misses. We have ~130 million of TLB misses. Miss/hit rate is 1% (which doesn’t look too bad at first). The numbers:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[~]# perf stat -e dTLB-loads,dTLB-load-misses,iTLB-load-misses,dTLB-store-misses -a -I 1000
</span></span><span class=line><span class=cl>#           time             counts unit events
</span></span><span class=line><span class=cl>...
</span></span><span class=line><span class=cl>    10.007352573      9,426,212,726      dTLB-loads                                                    
</span></span><span class=line><span class=cl>    10.007352573         99,328,930      dTLB-load-misses          #    1.04% of all dTLB cache hits   
</span></span><span class=line><span class=cl>    10.007352573         26,021,651      iTLB-load-misses                                              
</span></span><span class=line><span class=cl>    10.007352573         10,955,696      dTLB-store-misses                                             
</span></span><span class=line><span class=cl>...
</span></span></code></pre></td></tr></table></div></div><p>Let’s take a look how much those misses cost for the CPU:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[~]# perf stat -e cycles \
</span></span><span class=line><span class=cl>&gt;   -e cpu/event=0x08,umask=0x10,name=dcycles/ \
</span></span><span class=line><span class=cl>&gt;   -e cpu/event=0x85,umask=0x10,name=icycles/ \
</span></span><span class=line><span class=cl>&gt;   -a -I 1000
</span></span><span class=line><span class=cl>#           time             counts unit events
</span></span><span class=line><span class=cl>...
</span></span><span class=line><span class=cl>    12.007998332     61,912,076,685      cycles
</span></span><span class=line><span class=cl>    12.007998332      5,615,887,228      dcycles
</span></span><span class=line><span class=cl>    12.007998332      1,049,159,484      icycles
</span></span><span class=line><span class=cl>...
</span></span></code></pre></td></tr></table></div></div><p>Yes, you see it right! <strong>More than 10%</strong> of CPU cycles were spent doing the page table walking.</p><p>The following counters show us that we have 1 million RAM memory reads caused by TLB misses (which can be up to 100 ns each):</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[~]# perf stat -e cpu/event=0xbc,umask=0x18,name=dreads/ \
</span></span><span class=line><span class=cl>&gt;    -e cpu/event=0xbc,umask=0x28,name=ireads/ \
</span></span><span class=line><span class=cl>&gt;    -a -I 1000
</span></span><span class=line><span class=cl>#           time             counts unit events
</span></span><span class=line><span class=cl>...
</span></span><span class=line><span class=cl>     6.003683030          1,087,179      dreads
</span></span><span class=line><span class=cl>     6.003683030            100,180      ireads
</span></span><span class=line><span class=cl>...
</span></span></code></pre></td></tr></table></div></div><p>All of the above numbers are good to know, but they are quite “synthetic”. The most important metrics for an application developer are the application metrics. Let’s take a look at the application end-to-end latency metrics. Here are the application latency in microseconds gathered for a few minutes:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>&#34;max&#34; : 16414.672,
</span></span><span class=line><span class=cl>  &#34;mean&#34; : 1173.2799067016406,
</span></span><span class=line><span class=cl>  &#34;min&#34; : 52.112,
</span></span><span class=line><span class=cl>  &#34;p50&#34; : 696.885,
</span></span><span class=line><span class=cl>  &#34;p75&#34; : 1353.116,
</span></span><span class=line><span class=cl>  &#34;p95&#34; : 3769.844,
</span></span><span class=line><span class=cl>  &#34;p98&#34; : 5453.675,
</span></span><span class=line><span class=cl>  &#34;p99&#34; : 6857.375,
</span></span></code></pre></td></tr></table></div></div><h3 id=transparent-hugepages-is-on>Transparent Hugepages is on</h3><p>The comparison begins! Let’s turn the THP on:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>echo always &gt; /sys/kernel/mm/transparent_hugepage/enabled
</span></span><span class=line><span class=cl>echo always &gt; /sys/kernel/mm/transparent_hugepage/defrag # consider other options too
</span></span></code></pre></td></tr></table></div></div><p>And launch the JVM with the <code>-XX:+UseTransparentHugePages -XX:+UseLargePagesInMetaspace -XX:+AlwaysPreTouch</code> flags.</p><p>The quantitative metrics shows us that the number of TLB misses dropped by 6 times from ~130 million to ~20 million. Miss/hit rate dropped from 1% to 0.15%. Here are the numbers:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[~]# perf stat -e dTLB-loads,dTLB-load-misses,iTLB-load-misses,dTLB-store-misses -a -I 1000
</span></span><span class=line><span class=cl>#           time             counts unit events
</span></span><span class=line><span class=cl>     1.002351984     10,757,473,962      dTLB-loads                                                    
</span></span><span class=line><span class=cl>     1.002351984         15,743,582      dTLB-load-misses          #    0.15% of all dTLB cache hits  
</span></span><span class=line><span class=cl>     1.002351984          4,208,453      iTLB-load-misses                                              
</span></span><span class=line><span class=cl>     1.002351984          1,235,060      dTLB-store-misses
</span></span></code></pre></td></tr></table></div></div><p>The CPU cycles spent in the page table walking also dropped by 5 times from ~6.7B to ~1.3B. We spend only 2% of CPU time walking the page table. Numbers below:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[~]# perf stat -e cycles \
</span></span><span class=line><span class=cl>&gt;   -e cpu/event=0x08,umask=0x10,name=dcycles/ \
</span></span><span class=line><span class=cl>&gt;   -e cpu/event=0x85,umask=0x10,name=icycles/ \
</span></span><span class=line><span class=cl>&gt;   -a -I 1000
</span></span><span class=line><span class=cl>#           time             counts unit events
</span></span><span class=line><span class=cl>...
</span></span><span class=line><span class=cl>     8.006641482     55,401,975,112      cycles
</span></span><span class=line><span class=cl>     8.006641482      1,133,196,162      dcycles
</span></span><span class=line><span class=cl>     8.006641482        167,646,297      icycles
</span></span><span class=line><span class=cl>...
</span></span></code></pre></td></tr></table></div></div><p>And the RAM reads also dropped from 1 million to 350K:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[root@PRCAPISV0003L01 ~]# perf stat -e cpu/event=0xbc,umask=0x18,name=dreads/ \
</span></span><span class=line><span class=cl>&gt;    -e cpu/event=0xbc,umask=0x28,name=ireads/ \
</span></span><span class=line><span class=cl>&gt;    -a -I 1000
</span></span><span class=line><span class=cl>#           time             counts unit events
</span></span><span class=line><span class=cl>...
</span></span><span class=line><span class=cl>    12.007351895            342,228      dreads
</span></span><span class=line><span class=cl>    12.007351895             17,242      ireads
</span></span><span class=line><span class=cl>...
</span></span></code></pre></td></tr></table></div></div><p>Again, all the above numbers look good but the most important fact is how they affect our application. Here are the latency numbers:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>&#34;max&#34; : 16028.281,
</span></span><span class=line><span class=cl>  &#34;mean&#34; : 946.232869010599,
</span></span><span class=line><span class=cl>  &#34;min&#34; : 41.977000000000004,
</span></span><span class=line><span class=cl>  &#34;p50&#34; : 589.297,
</span></span><span class=line><span class=cl>  &#34;p75&#34; : 1080.305,
</span></span><span class=line><span class=cl>  &#34;p95&#34; : 2966.102,
</span></span><span class=line><span class=cl>  &#34;p98&#34; : 4288.5830000000005,
</span></span><span class=line><span class=cl>  &#34;p99&#34; : 5918.753,
</span></span></code></pre></td></tr></table></div></div><p>The difference between 95%% is almost 1 millisecond! Here’s how the 95%% difference looks on a dashboard side by side during time:</p><p><img src=/assets/grafana.png alt=Transparent%20Hugepages%20measuring%20the%20performance%20im/grafana.png></p><p>We just measured the performance improvement having Transparent Hugepages Support enabled. But as we know, it bears some maintenance overhead and risks of latency spikes. We surely need to measure them too. Let’s take a look at the <code>khugepaged</code> kernel thread that works on hugepages defragmentation. The probing was done for twenty-four hours or so. As you can see the maximum execution time is 6 milliseconds, there are quite a few runs that took more than 1 millisecond. This is a background thread but it locks pages it works with. Below is the histogram:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[~]# ./func_time_stats.stp &#39;kernel.function(&#34;khugepaged_scan_mm_slot&#34;)&#39; 60000 -o khugepaged_scan_mm_slot.log
</span></span><span class=line><span class=cl>[~]# tail khugepaged_scan_mm_slot.log
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Thu Aug 17 13:38:59 2017 CEST:
</span></span><span class=line><span class=cl> min:0us avg:321us max:6382us count:10834
</span></span><span class=line><span class=cl>value |-------------------------------------------------- count
</span></span><span class=line><span class=cl>    0 |@                                                   164
</span></span><span class=line><span class=cl>    1 |@                                                   197
</span></span><span class=line><span class=cl>    2 |@@@                                                 466
</span></span><span class=line><span class=cl>    4 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@  6074
</span></span><span class=line><span class=cl>    8 |@@@@@@                                              761
</span></span><span class=line><span class=cl>   16 |@@                                                  318
</span></span><span class=line><span class=cl>   32 |                                                     65
</span></span><span class=line><span class=cl>   64 |                                                     13
</span></span><span class=line><span class=cl>  128 |                                                      1
</span></span><span class=line><span class=cl>  256 |                                                      3
</span></span><span class=line><span class=cl>  512 |@@@                                                 463
</span></span><span class=line><span class=cl> 1024 |@@@@@@@@@@@@@@@@@@                                 2211
</span></span><span class=line><span class=cl> 2048 |                                                     85
</span></span><span class=line><span class=cl> 4096 |                                                     13
</span></span><span class=line><span class=cl> 8192 |                                                      0
</span></span><span class=line><span class=cl>16384 |                                                      0
</span></span></code></pre></td></tr></table></div></div><p>Another important kernel function is <code>__alloc_pages_slowpath</code>. It also can cause latency spikes if can’t find contiguous block of memory. The probing histogram looks good, the maximum allocation time was 288 microsecond. Having it running for hours or even days gives us some confidence that we won’t run into a huge spike.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>[~]# ./func_time_stats.stp &#39;kernel.function(&#34;__alloc_pages_slowpath&#34;)&#39; 60000 -o alloc_pages_slowpath.log
</span></span><span class=line><span class=cl>[~]# tail alloc_pages_slowpath.log
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Tue Aug 15 10:35:03 2017 CEST:
</span></span><span class=line><span class=cl> min:0us avg:2us max:288us count:6262185
</span></span><span class=line><span class=cl>value |-------------------------------------------------- count
</span></span><span class=line><span class=cl>    0 |@@@@                                                237360
</span></span><span class=line><span class=cl>    1 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@     2308083
</span></span><span class=line><span class=cl>    2 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@  2484688
</span></span><span class=line><span class=cl>    4 |@@@@@@@@@@@@@@@@@@@@@@                             1136503
</span></span><span class=line><span class=cl>    8 |@                                                    72701
</span></span><span class=line><span class=cl>   16 |                                                     22353
</span></span><span class=line><span class=cl>   32 |                                                       381
</span></span><span class=line><span class=cl>   64 |                                                         7
</span></span><span class=line><span class=cl>  128 |                                                       105
</span></span><span class=line><span class=cl>  256 |                                                         4
</span></span><span class=line><span class=cl>  512 |                                                         0
</span></span><span class=line><span class=cl> 1024 |                                                         0
</span></span></code></pre></td></tr></table></div></div><p>So why do Transparent Hugepages work well in this case? First of all, we see performance improvement because we work with large amount of memory. We don’t see high latency spikes because we don’t have memory pressure. There is plenty of RAM (256 GB), the JVM knows about THP, preallocates whole 200 GB heap at start and doesn’t resize it.</p><h2 id=conclusion>Conclusion</h2><p>Do not blindly follow any recommendation on the Internet, please! Measure, measure and measure again!</p><p>Transparent Hugepage Support is an optimization and can improve performance, but it has pitfalls and risks that can cause unexpected consequences. The purpose of this post is to provide techniques to measure possible improvement and manage risks. Linux kernel and its features evolve and some issues were addressed in latest kernels, e.g. with the “defer” defrag option, the OS falls back to a regular page, if it can’t allocate a large one.</p></article><hr><div class=page-end><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div></div><div id=contact_buttons><footer><p>Made by Jacky Zhao using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2022</p><ul><li><a href=/>Home</a></li><li><a href=https://twitter.com/_jzhao>Twitter</a></li><li><a href=https://github.com/jackyzha0>Github</a></li></ul></footer></div><script src=https://lzyerste.github.io/quartz/js/popover.e57188d2e4c06b0654e020b3a734bb62.min.js></script>
<script>initPopover("https://lzyerste.github.io/quartz")</script></div></body></html>